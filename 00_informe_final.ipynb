{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "...\n",
    "\n",
    "# Antecedentes\n",
    "...\n",
    "\n",
    "# Objetivos y Metricas de Evaluación\n",
    "...\n",
    "\n",
    "# Planteamiento del problema\n",
    "...\n",
    "\n",
    "# Desarrollo de la solución\n",
    "### EDA\n",
    "\n",
    "##### Metodologia\n",
    "\n",
    "Se hizo un analisis exploratorio sistematico relacionado a los roles de los jugadores; a de manera biyectiva, cuales son los puntos que pueden llegar a lograr.\n",
    "De esa manera medimos lo siguiente (Por rol):\n",
    "* La distribución de puntos que usualmente generan\n",
    "* Su distribucion de yardas recorridas o pases completados\n",
    "* Su precision en recepciones, intercepciones o patadas y la distancia de estos\n",
    "* Una comparacion de las anteriores estadisticas con la cantidad de puntos\n",
    "\n",
    "##### Hallazgos Clave\n",
    "<div align=\"center\">\n",
    "  <img src=\"imgs/plots/quaterback%20analytic.png\" width=\"700\"/>\n",
    "</div>\n",
    "...\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"imgs/plots/kicker%20analytic.png\" width=\"700\"/>\n",
    "</div>\n",
    "...\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"imgs/plots/wide%20receiver%20analytic.png\" width=\"700\"/>\n",
    "</div>\n",
    "...\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"imgs/plots/running%20back%20analytic.png\" width=\"700\"/>\n",
    "</div>\n",
    "...\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"imgs/plots/tight%20end%20analytic.png\" width=\"700\"/>\n",
    "</div>\n",
    "...\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"imgs/plots/defense%20analytic.png\" width=\"700\"/>\n",
    "</div>\n",
    "...\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"imgs/plots/pst%20distro.png\" width=\"700\"/>\n",
    "</div>\n",
    "...\n",
    "\n",
    "##### Variables cantidatas a ingenieria de caracteristicas\n",
    "Todas las variables categoricas son cantidatas a un OHE para su procesamiento.\n",
    "\n",
    "##### Riesgos detectados\n",
    "Algunas columnas pueden provocar data leakage ya que son reflejos de la variable objetivo \"FTPS\".\n",
    "\n",
    "### Data Wrangling\n",
    "Lista de transformaciones:\n",
    "* Etiquetado de posición - Se añade la columna Position a cada dataframe individual(DST, K, QB, RB, TE, WR). Justificacion: Necesitaremos reconocer posiciones cuando juntemos todos los df's para procesarlos. Alternativas consideradas: Procesar cada df individualmente pero debido al aumento de complejidad, descartado.\n",
    "* Unión de dataset - Concatenación de todos los dataframes en un solo dataset general. Justificación: Para hacer un procesamiento formal de los datos decisimos juntar a todos los jugadores de la liga en el mismo df. Alternativas consideradas: NA.\n",
    "* Limpieza inicial - Eliminación de columnas irrelevantes: Player, Team, FPTS, FPTS/G. Justificación: estas son las col que podian crear data leakage + col que no tienen efecto directo en los datos. Alternativa considerada: NA.\n",
    "* Conversión de tipos - Justificacion: en el caso que hubiera str que realmente eran int se decidio volver a transformar col con >50% en datos num. a num. solo para asegurar la limpieza de los datos. De misma manera pudimos clasificar los que no eran numericos. Alternativa considerada: NA.\n",
    "* Imputación de valores faltantes. Justificación: decidimos utilizar la mediana en vez de la media ya que en el deporte puede haber deportistas estrella o outliers practicamente por lo que la mediana nos servira para balancear ese fenomeno. Alternativa considerada: Utilizar la media pero fue descartada.\n",
    "* Codificación categórica OHE. Justificación: Es la manera mas directa de poder computar datos categoricos, fue utilizada por la complejidad de los datos y su buen rendimiento. Alternativa considerada: Mineria de Datos.\n",
    "\n",
    "Evidencias (Antes/Despues):\n",
    "* Antes:\n",
    "\n",
    "| Rank | Player                      | SACK | INT | FR | FF | DEF TD | SFTY | SPC TD | G  | ... | TD  | SACKS | ATT.1 | YDS.1 | TD.1 | FL  | 20+ | TGT | REC | Y/R |\n",
    "|------|-----------------------------|------|-----|----|----|--------|------|--------|----|-----|-----|-------|--------|--------|------|-----|-----|-----|-----|-----|\n",
    "| 1.0  | Houston Texans (HOU)        | 33.0 | 12.0| 7.0| 8.0| 2.0    | 0.0  | 0.0    | 11.0| ... | NaN | NaN   | NaN    | NaN    | NaN  | NaN | NaN | NaN | NaN | NaN |\n",
    "| 2.0  | Los Angeles Rams (LAR)      | 31.0 | 12.0| 7.0|10.0| 1.0    | 0.0  | 0.0    | 11.0| ... | NaN | NaN   | NaN    | NaN    | NaN  | NaN | NaN | NaN | NaN | NaN |\n",
    "| 3.0  | Seattle Seahawks (SEA)      | 36.0 | 9.0 | 4.0| 3.0| 2.0    | 0.0  | 2.0    | 11.0| ... | NaN | NaN   | NaN    | NaN    | NaN  | NaN | NaN | NaN | NaN | NaN |\n",
    "| 4.0  | Cleveland Browns (CLE)      | 42.0 | 9.0 | 6.0|10.0| 2.0    | 0.0  | 0.0    | 11.0| ... | NaN | NaN   | NaN    | NaN    | NaN  | NaN | NaN | NaN | NaN | NaN |\n",
    "| 5.0  | Pittsburgh Steelers (PIT)   | 34.0 | 9.0 |11.0|13.0| 3.0    | 0.0  | 0.0    | 11.0| ... | NaN | NaN   | NaN    | NaN    | NaN  | NaN | NaN | NaN | NaN | NaN |\n",
    "\n",
    "* Despues:\n",
    "\n",
    "| Rank | SACK | INT | FR  | FF  | DEF TD | SFTY | SPC TD | G   | FG  | ... | ROST_99.4% | ROST_99.6% | ROST_99.7% | ROST_99.8% | ROST_99.9% | Position_K | Position_QB | Position_RB | Position_TE | Position_WR |\n",
    "|------|------|-----|-----|-----|--------|------|--------|-----|-----|-----|------------|------------|------------|------------|------------|-------------|--------------|--------------|--------------||--------------|\n",
    "| 1.0  | 33.0 |12.0 | 7.0 | 8.0 | 2.0    | 0.0  | 0.0    |11.0 | 9.5 | ... | False      | False      | False      | False      | False      | False       | False        | False        | False        | False        |\n",
    "| 2.0  | 31.0 |12.0 | 7.0 |10.0 | 1.0    | 0.0  | 0.0    |11.0 | 9.5 | ... | False      | False      | False      | False      | False      | False       | False        | False        | False        | False        |\n",
    "| 3.0  | 36.0 | 9.0 | 4.0 | 3.0 | 2.0    | 0.0  | 2.0    |11.0 | 9.5 | ... | False      | False      | False      | False      | False      | False       | False        | False        | False        | False        |\n",
    "| 4.0  | 42.0 | 9.0 | 6.0 |10.0 | 2.0    | 0.0  | 0.0    |11.0 | 9.5 | ... | False      | False      | False      | False      | False      | False       | False        | False        | False        | False        |\n",
    "| 5.0  | 34.0 | 9.0 |11.0 |13.0 | 3.0    | 0.0  | 0.0    |11.0 | 9.5 | ... | False      | False      | False      | False      | False      | False       | False        | False        | False        | False        |\n",
    "\n",
    "Resultado final(df.info):\n",
    "\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 983 entries, 0 to 982\n",
    "Columns: 317 entries, Rank to Position_WR\n",
    "dtypes: bool(283), float64(34)\n",
    "memory usage: 532.9 KB\n",
    "None\n",
    "\n",
    "\n",
    "Ruta final del Dataset:\n",
    "* Antes:\n",
    "\"DraftFantasy/src/data/df.csv\"\n",
    "\n",
    "* Despues\n",
    "\"DraftFantasy/src/data/df_processed_eg.csv\"\n",
    "\n",
    "Referencia tecnica completa:\n",
    "\"DraftFantasy/src/notebooks/02_DataWrangling.ipynb\"\n",
    "\n",
    "### Entrenmamiento con MLFLOw\n",
    "\n",
    "Familia de modelos utilizada:\n",
    "* XGBoost\n",
    "* LightGBM\n",
    "* Random Forest\n",
    "\n",
    "Registro de MlFlow:\n",
    "La estrutura de los experimentos fue la siguiente, se hizo la busqueda de hiperparametros, 50 trials alternando entre los 3 modelos de esos 50 trials, se guarda el modelo con el mejor espacio de bisqueda que registro un menor rmse. Se registraron, el rmse, el r2 y el mae. Pero rmse fue la metrica seleccionada como criterio de uso. El mejor modelo se creo y se registro.\n",
    "\n",
    "Optimizacion de Hiperparametros:\n",
    "Se utilizo la libreria optuna, con un numero de evaluaciones de 50 trials. El espacio de busqueda ya fue descrito anteriormente.\n",
    "\n",
    "Evidencias(Mejores experimentos):\n",
    "<div align=\"center\">\n",
    "  <img src=\"imgs/ss/mlflow/best_experiments.PNG\" width=\"700\"/>\n",
    "</div>\n",
    "\n",
    "Artifacts registrados:\n",
    "Los artifacts que se crearon fue principalmente el preprocesador se puede encontrar en \"DraftFantasy/src/pipelines/artifacts\" como preprocessor.pkl\n",
    "\n",
    "### Selección del mejor modelo.\n",
    "\n",
    "Criterio Objetivo:\n",
    "\n",
    "Como se puede adelantar en nuestra anterior sección se selecciono el mejor modelo por medio del rmse minimizandolo.\n",
    "\n",
    "Comparación consolidada:\n",
    "\n",
    "| Run | Model    | n_estimators | max_depth | learning_rate | subsample | colsample_bytree | reg_lambda | reg_alpha | num_leaves |   RMSE   |   MAE   |    R²    |\n",
    "|-----|----------|--------------|-----------|----------------|-----------|-------------------|------------|-----------|-------------|----------|---------|----------|\n",
    "| 59  | xgboost  | 127          | 13        | 0.0978         | 0.5102    | 0.6810            | 0.0203     | 0.9403    | None        | 5.959179 | 2.609105| 0.979942 |\n",
    "| 111 | xgboost  | 283          | 4         | 0.0923         | 0.7553    | 0.5388            | 1.5395     | 1.1419    | None        | 6.365348 | 2.679624| 0.977115 |\n",
    "| 163 | xgboost  | 378          | 8         | 0.0943         | 0.5017    | 0.6147            | 0.1431     | 0.1255    | None        | 6.421486 | 2.498007| 0.976709 |\n",
    "| 215 | lightgbm | 445          | 9         | 0.0594         | 0.6994    | 0.6917            | 0.2016     | 5.5862    | 97          | 6.550088 | 2.903093| 0.975767 |\n",
    "| 0   | lightgbm | 362          | 9         | 0.0617         | 0.7830    | 0.9940            | 0.0072     | 0.2217    | 56          | 6.657549 | 2.998966| 0.974965 |\n",
    "\n",
    "Justificacion final: Los modelos presentados aqui fueron los modelos registrados, es decir. Lo mejor del espacio de busqueda para cada experimento. Aqui algo que modelos destacar es lo pequeño que es reg_lamada y lo bien que optimiza lo que sugiere que los cambios son por detalles menores en el juego.\n",
    "\n",
    "Registro del Modelo Ganador:\n",
    "\n",
    "El modelo ganador siempre es registrado como champion.\n",
    "\n",
    "### Orquestación\n",
    "\n",
    "Descripción del flujo automatizado:\n",
    "1. La data se pasa a la funcion de preprocesamiento que genera un artefacto llamado preprocessor.pkl que se usara para el uso en la API\n",
    "2. Los datos tratados se pasan a los optimizadores del espacio de busqueda.\n",
    "3. El modelo con los mejores hiperparametros es creado y evaluado.\n",
    "4. Esta información es guardada en el unity_catalog de Databricks.\n",
    "\n",
    "Comandos:\n",
    "\n",
    "python.exe DraftFantasy/src/pipelines/train_pipeline.py\n",
    "\n",
    "Manejo de fallos:\n",
    "\n",
    "Excepciones Manejadas con ValueError()\n",
    "\n",
    "Evidencias:\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"imgs/diagrams/train_pipeline_diagram.png\" width=\"700\"/>\n",
    "  <br>\n",
    "  <img src=\"imgs/ss/misc/train_flow_running.PNG\" width=\"700\"/>\n",
    "  <br>\n",
    "  <img src=\"imgs/ss/prefect/prefect_history.PNG\" width=\"700\"/>\n",
    "  <br>\n",
    "  <img src=\"imgs/ss/prefect/prefect_flow.PNG\" width=\"700\"/>\n",
    "</div>\n",
    "\n",
    "### Servir modelo (API con FastAPI)\n",
    "\n",
    "Objetivo del servicio:\n",
    "\n",
    "El objetivo del servicio es servir la mejor prospeccion de un jugador la proxima semana, asi otorgar un buen draft al jugador.\n",
    "\n",
    "Endpoints:\n",
    "\n",
    "* (/) root\n",
    "* (/health) health check\n",
    "* (/predict) predecir mejor jugador\n",
    "* (/predict_batch) predecir los mejores 10 jugadores\n",
    "\n",
    "Flujo del modelo:\n",
    "\n",
    "El flujo del modelo se puede apreciar en el siguiente diagrama\n",
    "<div align=\"center\">\n",
    "  <img src=\"imgs/diagrams/deploy_diagram.png\" width=\"700\"/>\n",
    "</div>\n",
    "\n",
    "Podemos ver que la API recibe la informacion ya preprocesada, llega una request (que se manejan a traves del sistema 200 success, 500 error) y colecta el modelo del model registry con anterioridad y ejecuta el algoritmo para mandar la respuesta a la UI.\n",
    "\n",
    "Referencia de codigo:\n",
    "\n",
    "La API se encuentra en \"DraftFantasy/src/backend/api.py\"\n",
    "\n",
    "Evidencia:\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"imgs/ss/api/API_ss_aws.PNG\" width=\"700\"/>\n",
    "</div>\n",
    "\n",
    "### Interfaz Gráfica (Streamlit)\n",
    "\n",
    "Objetivo:\n",
    "* Brindar al usuario el servicio de asistencia por ML para su Draft.\n",
    "* Brindar al servicio de otros servicios cuantitativos tradicionales, como mejor alineacion o calculo de valor en el trade.\n",
    "\n",
    "Componentes minimos:\n",
    "Iniciar tu session de Draft. Cada vez que pasen las rondas el modelo encontrara el mejor jugador disponible o diferentes opciones igual de buenas (batch).\n",
    "\n",
    "Indicaciones de ejecucion local:\n",
    "\n",
    "streamlit run DraftFantasy/src/frontend/app.py\n",
    "\n",
    "La UI se encuentra en \"DraftFantasy/src/frontend/app.py\"\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "  <video width=\"700\" controls>\n",
    "    <source src=\"imgs/ss/GUI/streamlit_aws.mp4\" type=\"video/mp4\">\n",
    "  </video>\n",
    "</div>\n",
    "\n",
    "\n",
    "### Contenerización del servicio\n",
    "\n",
    "Dockerfile backend:\n",
    "```\n",
    "FROM python:3.11-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY backend/api.py ./api.py\n",
    "\n",
    "COPY backend/requirements.txt ./requirements.txt\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "EXPOSE 8000\n",
    "\n",
    "CMD [\"uvicorn\", \"api:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "```\n",
    "\n",
    "\n",
    "Dockerfile frontend:\n",
    "```\n",
    "FROM python:3.11-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY frontend/app.py ./app.py\n",
    "\n",
    "COPY frontend/requirements.txt ./requirements.txt\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "EXPOSE 8501\n",
    "\n",
    "CMD [\"streamlit\", \"run\", \"app.py\", \"--server.address=0.0.0.0\", \"--server.port=8501\"]\n",
    "```\n",
    "\n",
    "docker-compose.yml\n",
    "\n",
    "```\n",
    "version: \"3.8\"\n",
    "\n",
    "services:\n",
    "  backend:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: backend/Dockerfile\n",
    "    ports:\n",
    "      - \"8000:8000\"\n",
    "    environment:\n",
    "      - DATABRICKS_HOST=${DATABRICKS_HOST}\n",
    "      - DATABRICKS_TOKEN=${DATABRICKS_TOKEN}\n",
    "    volumes:\n",
    "      - ./pipelines/artifacts/preprocessors:/app/preprocessors:ro\n",
    "    restart: unless-stopped\n",
    "\n",
    "  frontend:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: frontend/Dockerfile\n",
    "    ports:\n",
    "      - \"8501:8501\"\n",
    "    depends_on:\n",
    "      - backend\n",
    "    environment:\n",
    "      - API_URL=http://backend:8000\n",
    "    volumes:\n",
    "      - ./data:/app/data:ro\n",
    "    restart: unless-stopped\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"imgs/diagrams/docker_diagram.png\" width=\"700\"/>\n",
    "</div>\n",
    "\n",
    "### Despliegue del servicio en la nube\n",
    "\n",
    "Plataforma elegida:\n",
    "\n",
    "AWS\n",
    "\n",
    "Pasos:\n",
    "\n",
    "1. Iniciar una instancia de EC2 (Liberar puerto 8000 y 8501, apartar al menos 15 gib, OS: ubuntu)\n",
    "2. Ingresar a la computadora a traves de tu llave .pem previamente descargada o traves de la consola de aws.\n",
    "3. git clone (a este repositorio)\n",
    "4. Descargar docker-compose\n",
    "\n",
    "Para descargar docker-compose ejecutar los siguientes comandos en orden.\n",
    "\n",
    "* sudo apt update\n",
    "* sudo apt upgrade -y\n",
    "* sudo apt install -y apt-transport-https ca-certificates curl software-properties-common\n",
    "* curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n",
    "* sudo apt update\n",
    "* sudo apt install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin\n",
    "* sudo systemctl start docker\n",
    "* sudo systemctl enable docker\n",
    "* sudo usermod -aG docker $USER\n",
    "* exit\n",
    "\n",
    "Despues vuelves a acceder a la maquina, eso significa que se ha reiniciado.\n",
    "\n",
    "5. Acceder a DraftFantasy/src\n",
    "6. Crear tu archivo .env\n",
    "\n",
    "Para crear tu archivo .env sigue las siguientes instrucciones y comandos\n",
    "\n",
    "* nano .env\n",
    "* escribir DATABRICKS_HOST=tu_url /parse DATABRICKS_TOKEN=tu_token\n",
    "* ctrl + x\n",
    "* Guardar\n",
    "\n",
    "7. Ejecutar docker-compose up --build\n",
    "8. Esperar a que los contenedores se levantes\n",
    "9. Acceder a tus puertos a traves de la ip publica de AWS\n",
    "\n",
    "\n",
    "Evidencia:\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"imgs/ss/docker/ready_docker_aws.PNG\" width=\"700\"/>\n",
    "</div>\n",
    "\n",
    "Limpieza/Costos:\n",
    "\n",
    "para detener los contenedores ejecuta el siguiente comando:\n",
    "\n",
    "* docker-compose down\n",
    "\n",
    "Ahora para limpiar el cache y el almacenamiento ejecuta los siguientes pasos:\n",
    "\n",
    "\n",
    "* docker stop $(docker ps -aq)\n",
    "* docker rm $(docker ps -aq)\n",
    "* docker rmi $(docker images -q) -f\n",
    "* docker volume rm $(docker volume ls -q)\n",
    "* docker network prune -f\n",
    "* docker system df\n",
    "\n",
    "\n",
    "# Conclusiones y recomendaciones\n",
    "...\n",
    "\n",
    "# Referencias\n",
    "* https://docs.docker.com/\n",
    "* https://docs.astral.sh/uv/guides/package/\n",
    "* https://docs.databricks.com/aws/en/\n",
    "* https://fastapi.tiangolo.com/\n",
    "* https://www.prefect.io/\n",
    "* https://streamlit.io/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
